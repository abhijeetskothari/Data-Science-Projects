{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports here\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms,  models\nfrom collections import OrderedDict\nfrom PIL import Image\nimport seaborn as sns\nimport numpy as np\nimport time\nfrom PIL import Image\nimport glob\nfrom torch.autograd import Variable","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/segregated-leaves-images/Segregated Data/training data/'\nvalid_dir = '../input/segregated-leaves-images/Segregated Data/validation data/'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transforms for the training, validation dataset\ntraining_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                          transforms.RandomResizedCrop(224),\n                                          transforms.RandomHorizontalFlip(),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])\n    \n                                         ])\n\nvalidation_transforms=transforms.Compose([transforms.Resize(255),\n                                                      transforms.CenterCrop(224),\n                                                      transforms.ToTensor(),\n                                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                                           [0.229, 0.224, 0.225])\n    \n                                                    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the datasets with ImageFolder\n\n#Loading training dataset and validation dataset\ntrain_data = datasets.ImageFolder(train_dir, transform=training_transforms)\nvalidation_data=datasets.ImageFolder(valid_dir, transform=validation_or_testing_transforms)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the image datasets and the trainforms, define the dataloaders\n\n#DataLoader for training set\ntrain_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n#DataLoader for validation set\nvalidation_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label mapping\nimport json\nwith open('../input/cat-to-name/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Build and train your network\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#importing the pre-trained model\n\nmodel=models.densenet121(pretrained=True)\n#model=models.resnet50(pretrained=True)\n#models.vgg16(pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#freezing paramenter so that we do not backdrop through them\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a feed forward model \n\nclassifier= nn.Sequential(nn.Linear(1024, 256),\n                          nn.ReLU(),\n                          nn.Dropout(0.2),\n                          nn.Linear(256, 38),\n                          nn.LogSoftmax(dim=1)\n                         )\n\n#changing the classifier of pre-trained model with our feed-forward classifier\n\nmodel.classifier=classifier\n\ncriterion = nn.NLLLoss()\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\nmodel.to(device);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training the model\nepochs = 10\ntrain_losses, validation_losses = [], []\nfor e in range(epochs):\n    \n    running_loss = 0\n    i=0\n    for inputs, labels in train_dataloader:\n        \n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        \n    else:\n        validation_loss = 0\n        accuracy = 0\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in validation_dataloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                logps = model.forward(inputs)\n                batch_loss = criterion(logps, labels)\n\n                validation_loss += batch_loss.item()\n\n                # Calculate accuracy\n                ps = torch.exp(logps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                \n                \n        train_losses.append(running_loss/len(train_dataloader))\n        validation_losses.append(validation_loss/len(validation_dataloader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_dataloader)),\n              \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validation_dataloader)),\n              \"Validation Accuracy: {:.3f}\".format(accuracy/len(validation_dataloader)))\n        \n        \n        model.train()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictons:","metadata":{}},{"cell_type":"code","source":"def process_image(img): \n    # Resize\n    if img.size[0] > img.size[1]:\n        img.thumbnail((10000, 256))\n    else:\n        img.thumbnail((256, 10000))\n        \n        \n    # Crop \n    left_margin = (img.width-224)/2\n    bottom_margin = (img.height-224)/2\n    right_margin = left_margin + 224\n    top_margin = bottom_margin + 224\n    img = img.crop((left_margin, bottom_margin, right_margin,   \n                      top_margin))\n    \n    # Normalize\n    img = np.array(img)/255\n    mean = np.array([0.485, 0.456, 0.406]) #provided mean\n    std = np.array([0.229, 0.224, 0.225]) #provided std\n    img = (img - mean)/std\n    \n    \n    # Move color channels to first dimension as expected by PyTorch\n    img = img.transpose((2, 0, 1))\n    \n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#interate through the test folder and make prediction for every image\n#save then name of the image and the predicted label in a dictionary\n\nimage_and_labels={}\nfilenames=glob.glob('../input/testdata/TestFiles/*.jpg')\ncounter=1\n\nfor image_path in filenames:\n\n    #image number\n    image_num=image_path.split('/')[4].split('.')[0]\n    \n    #processing\n    image=Image.open(image_path)\n    img = process_image(image) \n    img = torch.from_numpy(img).type(torch.FloatTensor) \n    img.unsqueeze_(0)\n    i = img.to(device)\n    \n    #prediction\n    model.eval()\n    probs = torch.exp(model.forward(i))\n    top_probs, top_labs = probs.topk(1) \n    \n    #adding to the dictonary \n    image_and_labels[image_num]=str(top_labs.item())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving Output","metadata":{}},{"cell_type":"code","source":"#converting dictionary to a dataframe\ndf_img_lab=pd.DataFrame(list(image_and_labels.items()))\ndf_img_lab.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving the dataframe in a CSV file.\ndf_img_lab.to_csv('predicted_labels_final.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}